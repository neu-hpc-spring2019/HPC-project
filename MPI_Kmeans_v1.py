{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "#import sys\n",
    "#sys.path.append(\"/home/li.haolin/scratch/mpi4py-3.0.1/src\")\n",
    "\n",
    "#import all library we need to use\n",
    "#from numpy import *\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "#import matplotlib.pyplot as plt #comment this sentence\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size() #get the number of how many rank we have\n",
    "rank = comm.Get_rank() #get the rank name\n",
    "node_name = MPI.Get_processor_name() # get the name of the node\n",
    "#print(\"size =\",size)\n",
    "#process data\n",
    "#determine the value of K in Kmeans\n",
    "def set_K():\n",
    "    max_K= 10 # this means the largest K we will test in our program, default 10\n",
    "    print(\"Will try K from 1 to\",max_K,\", do you want to change it?\");\n",
    "    det_ew_K = input(\"y/n: \");\n",
    "    if(det_ew_K == \"y\"):\n",
    "        print(\"Please tell me the value of new K.\");\n",
    "        max_K = int(input(\"new_K: \"));\n",
    "    return max_K\n",
    "\n",
    "#calculate Euclid distance between two points\n",
    "#don't forget normalize your data before you use E distance\n",
    "def E_distance(point_a, point_b):\n",
    "    return sum(pow(point_a - point_b,2))#np.sqrt(sum(pow(point_a - point_b,2)))\n",
    "\n",
    "#set the center of each cluster\n",
    "def set_center(data,num_k):\n",
    "    # Madhu Yedla et al's method\n",
    "    #first check whether the dataset have negative value\n",
    "    #data should be array \n",
    "    data_pro = np.array(data)\n",
    "    for j in range(np.size(data_pro,1)):\n",
    "        if min(data_pro[:,j]) < 0:       #if dataset have negative value, then move the dataset\n",
    "            data_pro[:,j] = data_pro[:,j] - np.resize(min(data_pro[:,j]), np.size(data_pro,0))\n",
    "    #then calculate the distance from each point to the center of coordinator\n",
    "    distance = np.zeros(np.size(data_pro,0))\n",
    "    for i in range(np.size(data_pro,0)):\n",
    "        distance[i] = E_distance(data_pro[i,:], np.zeros(np.size(data_pro,1)))\n",
    "        #distance[1,i] = i  #save the point index of each distance\n",
    "    #order the distance\n",
    "    index = np.argsort(distance) #sort the number and get the original index\n",
    "    #divide the dataset to K different classes\n",
    "    num_per_class = int(np.size(data_pro,0)/num_k)\n",
    "    #then find the point which have the meidum distance in this class as the center  point of this classes\n",
    "    result = []\n",
    "    for k in range(0,np.size(data_pro,0),num_per_class+1):\n",
    "        result.append(index[int(k + num_per_class/2)]) #save the point index\n",
    "        \n",
    "    return result\n",
    "\n",
    "def find_center(data,k): \n",
    "    if np.size(data) != 0:\n",
    "        center = np.zeros(np.size(data,1)) #the center of dataset\n",
    "        for j in range(np.size(data,1)): #how many vertical lines we have\n",
    "            sum_h = 0  \n",
    "            for i in range(np.size(data,0)): #how many horizontal lines we have\n",
    "                sum_h = sum_h + data[i,j]\n",
    "            center[j] = sum_h / np.size(data,0)\n",
    "        return center\n",
    "    else:\n",
    "        return np.zeros(k)\n",
    "        \n",
    "def stop_or_not(center_new, center_old):\n",
    "    error = sum(np.array(center_new) - np.array(center_old))/np.size(center_new)\n",
    "    if error < 0.1:\n",
    "        return true\n",
    "    else:\n",
    "        return false\n",
    "    \n",
    "##################this two functions is used to calculate SSE#####   \n",
    "def cal_SSE_part(data,k):\n",
    "    SSE = 0\n",
    "    center = find_center(np.array(data),k)\n",
    "    for i in range(np.size(data,1)): #how many points in this cluster\n",
    "        for j in range(i+1,np.size(data,1)): ################this part need mpi\n",
    "            SSE = SSE + E_distance(data[i][:],center)\n",
    "    return SSE/(2*np.size(data,1))\n",
    "    #return SSE\n",
    "def cal_SSE(data,k):\n",
    "    SSE = 0\n",
    "    #print(\"data have \",np.size(data,0), \"clusters\")\n",
    "    for i in range(np.size(data,0)):\n",
    "        part = data[i]\n",
    "        SSE = SSE + cal_SSE_part(part,k)\n",
    "    return SSE\n",
    "##################this two functions is used to calculate SSE#####   \n",
    "\n",
    "def kmeans(data,k):\n",
    "    #k = set_K()\n",
    "    r = 0 # how many round we will run for kmeans\n",
    "    initial_point_index = set_center(data,k)\n",
    "    initial_point = []\n",
    "    group = []\n",
    "    group_original = []\n",
    "    past_center = []\n",
    "    center = []\n",
    "    for i in range(k):\n",
    "        initial_point.append(data[initial_point_index[i]]) \n",
    "        group.append([]) #initialize group\n",
    "        group_original.append([]) #initialize group\n",
    "        center.append(np.zeros(np.size(data,1))) #initialize the center array\n",
    "        past_center.append(np.ones(np.size(data,1))) #initialize the past_center array\n",
    "    #the core of kmeans\n",
    "    while(r < 15): #(stop_or_not(center,past_center)): \n",
    "        group = group_original #refresh group each time\n",
    "        for i in range(np.size(data,0)):\n",
    "            min_d = np.inf\n",
    "            g = 0\n",
    "            for j in range(k):\n",
    "                if min_d > E_distance(data[i,:],np.array(initial_point[j][:])):\n",
    "                    min_d = E_distance(data[i,:],np.array(initial_point[j][:]))\n",
    "                    g = j\n",
    "            group[g].append(data[i,:]) #generate new group\n",
    "        past_center = center\n",
    "        for i in range(k):\n",
    "            initial_point[i] = find_center(np.array(group[i])) #refresh center point\n",
    "        r = r + 1\n",
    "    return group\n",
    "#########################\n",
    "#generate dataset to test\n",
    "mean = [0,5]\n",
    "cov = [[1,0],[0,1]]\n",
    "mean1 = [10,8]\n",
    "cov1 = [[1,0],[0,1]]\n",
    "mean2 = [5,0]\n",
    "cov2 = [[1,0],[0,1]]\n",
    "mean3 = [5,-8]\n",
    "cov3 = [[1,0],[0,1]]\n",
    "k = 4\n",
    "data = np.random.multivariate_normal(mean, cov, 5000)\n",
    "data1 = np.random.multivariate_normal(mean1, cov1, 5000)\n",
    "data2 = np.random.multivariate_normal(mean2, cov2, 5000)\n",
    "data3 = np.random.multivariate_normal(mean3, cov3, 5000)\n",
    "data_all = np.concatenate((data,data1,data2,data3),axis = 0) #the final dataset to test\n",
    "#########################\n",
    "\n",
    "# warning: didn't consider the condition when the number of processors we use smaller than the number in dataset\n",
    "#use mpi parallel run kmeans\n",
    "# repeat: means how many times you will run kmeans when k is not change\n",
    "# size: how many task (or node) we have right now\n",
    "# rank: which node we are using right now\n",
    "#read size and node number(rank)\n",
    "\n",
    "data = data_all # we already konw data right now\n",
    "if rank == 0:\n",
    "  k_use = set_K()\n",
    "#k_use = 5 #how many class you have\n",
    "  print(\"How many times you will run kmeans when k is not change?\");\n",
    "  repeat = int(input(\"Repeat: \"));\n",
    "#def kmeans_MPI(k, data, repeat):\n",
    "  final_k = 0\n",
    "  SSE = np.zeros(k_use)\n",
    "  final_SSE = np.inf\n",
    "  \n",
    "if rank == 0:\n",
    "        #the core of kmeans\n",
    "    for i in range(1,size):\n",
    "    \tcomm.send(k_use,dest = i)\n",
    "    \tcomm.send(repeat,dest = i)\n",
    "    for k in range(1,k_use+1):\n",
    "        print(\"test \", k, \"th cluster right now\")\n",
    "        r = 0\n",
    "        initial_point_index = set_center(data,k)\n",
    "        initial_point = []\n",
    "        group = []\n",
    "        #group_original = []\n",
    "        #past_center = []\n",
    "        #center = []\n",
    "        print(\"size of nodes this machine have: \",size)\n",
    "        for i in range(k):\n",
    "          initial_point.append(data[initial_point_index[i]]) \n",
    "          #group.append([]) #initialize group\n",
    "          #group_original.append([]) #initialize group\n",
    "          #center.append(np.zeros(np.size(data,1))) #initialize the center array\n",
    "          #past_center.append(np.ones(np.size(data,1))) #initialize the past_center array\n",
    "        while r < repeat: #this is where kmeans run\n",
    "            group = [[] for i in range(k)]\n",
    "            #new_data_start = 0\n",
    "            #group = group_original #refresh group each time\n",
    "            #print(group)\n",
    "            for i in range(int(np.size(data,0)/(size-rank))): #take database apart\n",
    "                min_d = np.inf\n",
    "                g = 0\n",
    "                for j in range(k):\n",
    "                    if min_d > E_distance(data[i,:],np.array(initial_point[j][:])):\n",
    "                        min_d = E_distance(data[i,:],np.array(initial_point[j][:]))\n",
    "                        g = j\n",
    "                group[g].append(data[i,:]) #generate new group\n",
    "            new_data_start = int(np.size(data,0)/(size-rank)) #this size will used in other thread\n",
    "            if(size > 1):\n",
    "                for i in range(1,size): # send data to other processor\n",
    "                    comm.send(np.size(data,0),dest = i)\n",
    "                    #comm.send(data,dest = i)\n",
    "                    if i != 1:\n",
    "                        new_data_start = new_data_start + int((np.size(data,0) - new_data_start)/(size-i+1))\n",
    "                    #print(\"new_data_start before send = \", new_data_start)\n",
    "                    comm.send(new_data_start,dest = i)\n",
    "                    comm.send(initial_point,dest = i)\n",
    "                    #comm.send(k,dest = i)\n",
    "                    \n",
    "\n",
    "                #comm.send(group) #??????\n",
    "\n",
    "                for i in range(1,size): # receive data from other processor\n",
    "                    group_sub = comm.recv(source = i)\n",
    "                    for j in range(k):\n",
    "                    \tif np.size(group_sub[j]) != 0:\n",
    "                        \t#print(\"group[\",j,\"] size= \",np.size(group[j]),\"group_sub[\",j,\"] size=\",np.size(group_sub[j]))\n",
    "                        \tif(np.size(group[j]) != 0):\n",
    "                        \t\tgroup[j] = np.vstack((group[j],group_sub[j])) #have some problem?????????????????????\n",
    "                        \telse:\n",
    "                        \t\tgroup[j] = group_sub[j]\n",
    "\n",
    "            #find center\n",
    "            #past_center = center\n",
    "            for i in range(k):\n",
    "                initial_point[i] = find_center(np.array(group[i]),np.size(data,1)) #refresh center point\n",
    "\n",
    "            r = r + 1\n",
    "        ##plot the figure\n",
    "            ##print(initial_point)\n",
    "        a = cal_SSE(group,k)\n",
    "        if final_SSE > a:\n",
    "          final_SSE = a\n",
    "          final_k = k\n",
    "        SSE[k-1] = a    \n",
    "        #return group\n",
    "        \n",
    "        ##for i in range(np.size(group,0)):\n",
    "        ##    a = np.array(group[i])\n",
    "           ##plt.figure(i)\n",
    "        ##    plt.plot(a[:,0],a[:,1],'.')\n",
    "        ##plot center\n",
    "        ##for i in range(k):\n",
    "            ##plt.plot(initial_point[i][0],initial_point[i][1],'+')\n",
    "if rank > 0:\n",
    "    k_use = comm.recv(source = 0)\n",
    "    repeat = comm.recv(source = 0)\n",
    "    for k in range(1,k_use+1):\n",
    "    \tr = 0\n",
    "    \twhile(r < repeat):\n",
    "    \t\tdata_size = comm.recv(source = 0)\n",
    "     \t\t#data = comm.recv(source = 0)\n",
    "    \t\tnew_data_start = comm.recv(source = 0)\n",
    "    \t\tinitial_point = comm.recv(source = 0)\n",
    "    \t\t#k = comm.recv(source = 0)\n",
    "    \t\tgroup = []\n",
    "    \t\tgroup = [[] for i in range(k)] #initialize group\n",
    "    \t\t#print(\"new_data_start = \",new_data_start, \" in rank:\",rank)\n",
    "    \t\tfor i in range(new_data_start,new_data_start+int((np.size(data,0) - new_data_start)/(size-rank))): #take database apart\n",
    "        \t\tmin_d = np.inf\n",
    "        \t\tg = 0\n",
    "        \t\tfor j in range(k):\n",
    "            \t\t\tif min_d > E_distance(data[i,:],np.array(initial_point[j][:])):\n",
    "                \t\t\tmin_d = E_distance(data[i,:],np.array(initial_point[j][:]))\n",
    "                \t\t\tg = j\n",
    "        \t\tgroup[g].append(data[i,:]) #generate new group\n",
    "            \t#new_data_size = new_data_size - new_data_size/(size-rank) #this size will used in other thread\n",
    "    \t\tr = r + 1\n",
    "    \t\tcomm.send(group, dest = 0)\n",
    "        \n",
    "##kmeans_MPI(k, data, repeat)\n",
    "##final_k = 0\n",
    "##SSE = np.zeros(k_use)\n",
    "##final_SSE = np.inf\n",
    "##for k in range(1,k_use+1):\n",
    "  #if rank == 0:\n",
    "    ##group = []\n",
    "    ##group = kmeans_MPI(k, data, repeat)\n",
    "      #a = cal_SSE(group,k)\n",
    "      #if final_SSE > a:\n",
    "      #    final_SSE = a\n",
    "      #    final_k = k\n",
    "      #SSE[k-1] = a\n",
    "      #gap = np.log(SSE)\n",
    "    ##for i in range(np.size(group,0)):\n",
    "    ##    a = np.array(group[i])\n",
    "    ##    plt.figure(k)\n",
    "    ##    plt.plot(a[:,0],a[:,1],'.')\n",
    "##plt.figure(k+1)\n",
    "##plt.plot(np.array(range(1,k_use+1)),SSE,'-')\n",
    "if rank == 0:\n",
    "    print(\"final_SSE are:\",final_SSE)\n",
    "    print(\"The dataset may have \",final_k,\" clusters\")\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "#plt.plot(np.array(range(1,k_use+1)),SSE,'-')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
